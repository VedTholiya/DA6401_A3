{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T06:58:16.680377Z",
     "iopub.status.busy": "2025-05-19T06:58:16.680087Z",
     "iopub.status.idle": "2025-05-19T06:58:25.913812Z",
     "shell.execute_reply": "2025-05-19T06:58:25.908113Z",
     "shell.execute_reply.started": "2025-05-19T06:58:16.680353Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.19.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/site-packages (from wandb) (4.3.8)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0\n",
      "  Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.10/site-packages (from wandb) (2.11.4)\n",
      "Collecting sentry-sdk>=2.0.0\n",
      "  Downloading sentry_sdk-2.28.0-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.7/341.7 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting setproctitle\n",
      "  Downloading setproctitle-1.3.6-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/site-packages (from wandb) (7.0.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/site-packages (from wandb) (4.13.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.10/site-packages (from wandb) (5.29.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from wandb) (80.3.1)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.10/site-packages (from pydantic<3->wandb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.10/site-packages (from pydantic<3->wandb) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
      "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.12 gitpython-3.1.44 sentry-sdk-2.28.0 setproctitle-1.3.6 smmap-5.0.2 wandb-0.19.11\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-19T07:00:12.942796Z",
     "iopub.status.busy": "2025-05-19T07:00:12.942553Z",
     "iopub.status.idle": "2025-05-19T07:00:20.501434Z",
     "shell.execute_reply": "2025-05-19T07:00:20.500855Z",
     "shell.execute_reply.started": "2025-05-19T07:00:12.942769Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T07:03:02.929327Z",
     "iopub.status.busy": "2025-05-19T07:03:02.929068Z",
     "iopub.status.idle": "2025-05-19T07:03:02.933960Z",
     "shell.execute_reply": "2025-05-19T07:03:02.933227Z",
     "shell.execute_reply.started": "2025-05-19T07:03:02.929309Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T07:03:03.948119Z",
     "iopub.status.busy": "2025-05-19T07:03:03.947431Z",
     "iopub.status.idle": "2025-05-19T07:03:03.953544Z",
     "shell.execute_reply": "2025-05-19T07:03:03.952810Z",
     "shell.execute_reply.started": "2025-05-19T07:03:03.948095Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.char2index = {'#': 0, '$': 1, '^': 2}  # # for padding, $ for unknown, ^ for start\n",
    "        self.char2count = {'#': 1, '$': 1, '^': 1}\n",
    "        self.index2char = {0: '#', 1: '$', 2: '^'}\n",
    "        self.n_chars = 3  # Count\n",
    "        self.data = {}\n",
    "    \n",
    "    def addWord(self, word):\n",
    "        for char in word:\n",
    "            self.addChar(char)\n",
    "\n",
    "    def addChar(self, char):\n",
    "        if char not in self.char2index:\n",
    "            self.char2index[char] = self.n_chars\n",
    "            self.char2count[char] = 1\n",
    "            self.index2char[self.n_chars] = char\n",
    "            self.n_chars += 1\n",
    "        else:\n",
    "            self.char2count[char] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T07:03:05.551608Z",
     "iopub.status.busy": "2025-05-19T07:03:05.551023Z",
     "iopub.status.idle": "2025-05-19T07:03:05.555512Z",
     "shell.execute_reply": "2025-05-19T07:03:05.554981Z",
     "shell.execute_reply.started": "2025-05-19T07:03:05.551585Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Return max length of input and output words\n",
    "def maxLength(data):\n",
    "    ip_mlen, op_mlen = 0, 0\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        input = data[0][i]\n",
    "        output = data[1][i]\n",
    "        if(len(input) > ip_mlen):\n",
    "            ip_mlen = len(input)\n",
    "        if(len(output) > op_mlen):\n",
    "            op_mlen = len(output)\n",
    "\n",
    "    return ip_mlen, op_mlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T07:03:06.790661Z",
     "iopub.status.busy": "2025-05-19T07:03:06.790380Z",
     "iopub.status.idle": "2025-05-19T07:03:06.794180Z",
     "shell.execute_reply": "2025-05-19T07:03:06.793492Z",
     "shell.execute_reply.started": "2025-05-19T07:03:06.790640Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T07:03:08.226931Z",
     "iopub.status.busy": "2025-05-19T07:03:08.226161Z",
     "iopub.status.idle": "2025-05-19T07:03:08.232932Z",
     "shell.execute_reply": "2025-05-19T07:03:08.232210Z",
     "shell.execute_reply.started": "2025-05-19T07:03:08.226895Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess(data, input_lang, output_lang):\n",
    "    maxlenInput, maxlenOutput = maxLength(data)\n",
    "    # We use maxlenInput as 26 since it is the maximum of all input len\n",
    "    maxlenInput = 26\n",
    "    input = numpy.zeros((len(data), maxlenInput + 1))\n",
    "    output = numpy.zeros((len(data), maxlenOutput + 2))\n",
    "    maxlenInput, maxlenOutput = maxLength(data)\n",
    "    unknown = input_lang.char2index['$']\n",
    "    for i in range(len(data)):\n",
    "        op = '^' + data[1][i]\n",
    "        ip = data[0][i].ljust(maxlenInput + 1, '#')\n",
    "        op = op.ljust(maxlenOutput + 2, '#')\n",
    "\n",
    "        for index, char in enumerate(ip):\n",
    "            if input_lang.char2index.get(char) is not None:\n",
    "                input[i][index] = input_lang.char2index[char]\n",
    "            else:\n",
    "                input[i][index] = unknown\n",
    "\n",
    "        for index, char in enumerate(op):\n",
    "            if output_lang.char2index.get(char) is not None:\n",
    "                output[i][index] = output_lang.char2index[char]\n",
    "            else:\n",
    "                output[i][index] = unknown \n",
    "\n",
    "    print(input.shape)\n",
    "    print(output.shape)\n",
    "\n",
    "    return TensorDataset(torch.from_numpy(input), torch.from_numpy(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T07:03:10.079036Z",
     "iopub.status.busy": "2025-05-19T07:03:10.078764Z",
     "iopub.status.idle": "2025-05-19T07:03:10.085160Z",
     "shell.execute_reply": "2025-05-19T07:03:10.084376Z",
     "shell.execute_reply.started": "2025-05-19T07:03:10.079015Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def loadData(lang):\n",
    "    train_df = pd.read_csv(f\"{DATA_PATH}/{lang}/lexicons/{lang}.translit.sampled.train.tsv\", sep='\\t', header=None)\n",
    "    val_df = pd.read_csv(f\"{DATA_PATH}/{lang}/lexicons/{lang}.translit.sampled.dev.tsv\", sep='\\t', header=None)\n",
    "    test_df = pd.read_csv(f\"{DATA_PATH}/{lang}/lexicons/{lang}.translit.sampled.test.tsv\", sep='\\t', header=None)\n",
    "    \n",
    "    # Replace NaN values with empty strings and ensure all values are strings\n",
    "    train_df = train_df.fillna('').astype(str)\n",
    "    val_df = val_df.fillna('').astype(str)\n",
    "    test_df = test_df.fillna('').astype(str)\n",
    "    \n",
    "    input_lang = Lang('eng')\n",
    "    output_lang = Lang(lang)\n",
    "    \n",
    "    # Add the words to the respective languages\n",
    "    for i in range(len(train_df)):\n",
    "        input_lang.addWord(train_df[0][i])\n",
    "        output_lang.addWord(train_df[1][i])\n",
    "\n",
    "    trainDataset = preprocess(train_df, input_lang, output_lang)\n",
    "    testDataset = preprocess(test_df, input_lang, output_lang)\n",
    "    valDataset = preprocess(val_df, input_lang, output_lang)\n",
    "\n",
    "    return trainDataset, testDataset, valDataset, input_lang, output_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T07:03:12.148042Z",
     "iopub.status.busy": "2025-05-19T07:03:12.147748Z",
     "iopub.status.idle": "2025-05-19T07:03:12.151663Z",
     "shell.execute_reply": "2025-05-19T07:03:12.150913Z",
     "shell.execute_reply.started": "2025-05-19T07:03:12.148020Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"/kaggle/input/dakshina-hindi/dakshina_dataset_v1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T07:03:19.875852Z",
     "iopub.status.busy": "2025-05-19T07:03:19.875297Z",
     "iopub.status.idle": "2025-05-19T07:03:22.225991Z",
     "shell.execute_reply": "2025-05-19T07:03:22.225385Z",
     "shell.execute_reply.started": "2025-05-19T07:03:19.875832Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/dakshina-hindi/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainData, testData, valData, ipLang, opLang \u001b[38;5;241m=\u001b[39m \u001b[43mloadData\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m, in \u001b[0;36mloadData\u001b[1;34m(lang)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloadData\u001b[39m(lang):\n\u001b[1;32m----> 2\u001b[0m     train_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mDATA_PATH\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/lexicons/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.translit.sampled.train.tsv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     val_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATA_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlang\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/lexicons/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlang\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.translit.sampled.dev.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m     test_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATA_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlang\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/lexicons/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlang\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.translit.sampled.test.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/dakshina-hindi/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv'"
     ]
    }
   ],
   "source": [
    "trainData, testData, valData, ipLang, opLang = loadData('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T07:03:23.209008Z",
     "iopub.status.busy": "2025-05-19T07:03:23.208476Z",
     "iopub.status.idle": "2025-05-19T07:03:23.218950Z",
     "shell.execute_reply": "2025-05-19T07:03:23.218237Z",
     "shell.execute_reply.started": "2025-05-19T07:03:23.208985Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, embedding_size, # input_size is size of input language dictionary\n",
    "                 num_layers, cell_type,\n",
    "                  bidirectional, dropout, batch_size) :\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size  # size of an hidden state representation\n",
    "        self.num_layers = num_layers   \n",
    "        self.bidirectional = True if bidirectional == 'Yes' else False\n",
    "        self.batch_size = batch_size\n",
    "        self.cell_type = cell_type\n",
    "        self.embedding_size=embedding_size\n",
    "\n",
    "        # this adds the embedding layer\n",
    "        self.embedding = nn.Embedding(num_embeddings=input_size,embedding_dim= embedding_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # this adds the Neural Network layer for the encoder\n",
    "        if self.cell_type == \"GRU\":\n",
    "            self.rnn = nn.GRU(embedding_size, hidden_size, num_layers=num_layers, bidirectional=self.bidirectional, dropout=dropout)\n",
    "        elif self.cell_type == \"LSTM\":\n",
    "            self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers=num_layers, bidirectional=self.bidirectional, dropout=dropout)\n",
    "        else:\n",
    "            self.rnn = nn.RNN(embedding_size, hidden_size, num_layers=num_layers, bidirectional=self.bidirectional, dropout=dropout)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "    # input shape: (seq_len, batch_size)\n",
    "        embedded = self.embedding(input.long())  # shape: (seq_len, batch_size, embedding_size)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        # No need to reshape since embedding output is already (seq_len, batch_size, embedding_size)\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        \n",
    "        if self.bidirectional:\n",
    "            if self.cell_type == \"LSTM\":\n",
    "                hidden_state = hidden[0].view(2, self.num_layers, self.batch_size, self.hidden_size)\n",
    "                cell_state = hidden[1].view(2, self.num_layers, self.batch_size, self.hidden_size)\n",
    "                hidden = (torch.add(hidden_state[0], hidden_state[1]) / 2, torch.add(cell_state[0], cell_state[1]) / 2)\n",
    "            else:\n",
    "                hidden = hidden.view(2, self.num_layers, self.batch_size, self.hidden_size)\n",
    "                hidden = torch.add(hidden[0], hidden[1]) / 2\n",
    "            \n",
    "            split_tensor = torch.split(output, self.hidden_size, dim=-1)\n",
    "            output = torch.add(split_tensor[0], split_tensor[1]) / 2\n",
    "    \n",
    "        return output, hidden\n",
    "\n",
    "    # initializing the initial hidden state for the encoder\n",
    "    def initHidden(self, batch_size=None):\n",
    "        if batch_size is None:\n",
    "            batch_size = self.batch_size\n",
    "        num_directions = 2 if self.bidirectional else 1\n",
    "        if self.cell_type == \"LSTM\":\n",
    "            return (\n",
    "                torch.zeros(self.num_layers * num_directions, batch_size, self.hidden_size, device=device),\n",
    "                torch.zeros(self.num_layers * num_directions, batch_size, self.hidden_size, device=device)\n",
    "            )\n",
    "        else:\n",
    "            return torch.zeros(self.num_layers * num_directions, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T07:03:25.171677Z",
     "iopub.status.busy": "2025-05-19T07:03:25.170981Z",
     "iopub.status.idle": "2025-05-19T07:03:25.177352Z",
     "shell.execute_reply": "2025-05-19T07:03:25.176741Z",
     "shell.execute_reply.started": "2025-05-19T07:03:25.171651Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, embedding_size, num_layers, # output size is the size of output language dictionary\n",
    "                 cell_type, dropout, batch_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.cell_type = cell_type.lower()\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding_size=embedding_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
    "        # self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        if self.cell_type == \"gru\":\n",
    "            self.rnn = nn.GRU(embedding_size, hidden_size, num_layers=num_layers)\n",
    "        elif self.cell_type == \"lstm\":\n",
    "            self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers=num_layers)\n",
    "        else:\n",
    "            self.rnn = nn.RNN(embedding_size, hidden_size, num_layers=num_layers)\n",
    "\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, input, hidden): # input shape (1, batch_size)\n",
    "        embedded = self.embedding(input.long()).view(-1, self.batch_size, self.embedding_size)\n",
    "        # # shape (1, batch_size, embedding_size)\n",
    "        output = F.relu(embedded)\n",
    "        output, hidden = self.rnn(output, hidden) # output shape (1, batch_size, hidden_size)\n",
    "        output = self.softmax(self.out(output)) # shape (1, batch_size, output_size)\n",
    "        return output, hidden\n",
    "\n",
    "    # not needed since hidden will be provided by the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T07:03:27.215685Z",
     "iopub.status.busy": "2025-05-19T07:03:27.215112Z",
     "iopub.status.idle": "2025-05-19T07:03:27.223772Z",
     "shell.execute_reply": "2025-05-19T07:03:27.223119Z",
     "shell.execute_reply.started": "2025-05-19T07:03:27.215661Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AttentionDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, embedding_size, num_layers,\n",
    "                 cell_type, dropout, batch_size, max_length):\n",
    "        super(AttentionDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.cell_type = cell_type\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.max_length = max_length\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
    "        self.dropout = nn.Dropout(self.dropout)\n",
    "        self.attention = nn.Linear(hidden_size + embedding_size, self.max_length)\n",
    "        self.attention_combine = nn.Linear(hidden_size + embedding_size, hidden_size)\n",
    "\n",
    "        if self.cell_type == \"GRU\":\n",
    "            self.rnn = nn.GRU(hidden_size, hidden_size, num_layers=num_layers)\n",
    "        elif self.cell_type == \"LSTM\":\n",
    "            self.rnn = nn.LSTM(hidden_size, hidden_size, num_layers=num_layers)\n",
    "        else:\n",
    "            self.rnn = nn.RNN(hidden_size, hidden_size, num_layers=num_layers)\n",
    "\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs): #input shape (1, batch_size)\n",
    "        embedded = self.embedding(input.long()).view(-1, self.batch_size, self.embedding_size) \n",
    "        # embedded shape (1, batch_size, embedding_size)\n",
    "        embedded = F.relu(embedded)\n",
    "\n",
    "        # Compute attention scores\n",
    "        if self.cell_type == \"LSTM\":\n",
    "            attn_hidden = torch.mean(hidden[0], dim=0)\n",
    "        else:\n",
    "            attn_hidden = torch.mean(hidden, dim = 0)\n",
    "        attn_scores = self.attention(torch.cat((embedded, attn_hidden.unsqueeze(0)), dim=2)) # attn_scores shape (1, batch_size, max_length)\n",
    "        \n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)  # attn_scores shape (1, 16, 25)\n",
    "        \n",
    "\n",
    "        # Apply attention weights to encoder outputs\n",
    "        attn_applied = torch.bmm(attn_weights.transpose(0, 1), encoder_outputs.transpose(0, 1))\n",
    "        \n",
    "        # Combine attention output and embedded input\n",
    "        combined = torch.cat((embedded, attn_applied.transpose(0, 1)), dim=2)\n",
    "        combined = self.attention_combine(combined)\n",
    "        combined = F.relu(combined) # shape (1, batch_size, hidden_size)\n",
    "\n",
    "        # Run through the RNN\n",
    "        output, hidden = self.rnn(combined, hidden)\n",
    "        # output shape: (1, batch_size, hidden_size)\n",
    "\n",
    "        # Pass through linear layer and softmax activation\n",
    "        output = self.out(output)  # shape: (1, batch_size, output_size)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden, attn_weights.transpose(0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T07:03:29.590304Z",
     "iopub.status.busy": "2025-05-19T07:03:29.590036Z",
     "iopub.status.idle": "2025-05-19T07:03:29.594819Z",
     "shell.execute_reply": "2025-05-19T07:03:29.594041Z",
     "shell.execute_reply.started": "2025-05-19T07:03:29.590284Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def count_exact_matches(pred, target):\n",
    "    \"\"\"\n",
    "    Counts the number of rows in preds tensor that match exactly with each row in y tensor.\n",
    "    pred: tensor of shape (batch_size, seq_len-1)\n",
    "    y: tensor of shape (batch_size, seq_len-1)\n",
    "    \"\"\"\n",
    "    \n",
    "    count=0;\n",
    "    for i in range(pred.shape[0]):\n",
    "      flag = True\n",
    "      for j in range(pred.shape[1]):\n",
    "        if(target[i][j]!=pred[i][j]):\n",
    "          flag=False\n",
    "          break;\n",
    "         \n",
    "      if(flag):\n",
    "        count+=1;\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T07:03:32.305303Z",
     "iopub.status.busy": "2025-05-19T07:03:32.304814Z",
     "iopub.status.idle": "2025-05-19T07:03:32.316419Z",
     "shell.execute_reply": "2025-05-19T07:03:32.315705Z",
     "shell.execute_reply.started": "2025-05-19T07:03:32.305279Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(data,encoder, decoder,output_size,batch_size,hidden_size,num_layers_encoder,num_layers_decoder, cell_type, attention):\n",
    "    \n",
    "\n",
    "\n",
    "    running_loss = 0\n",
    "    correct =0\n",
    "    \n",
    "    loader = DataLoader(data, batch_size=batch_size)\n",
    "    loss_fun = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "    seq_len = 0\n",
    "\n",
    "    atten_weights = torch.zeros(1,21, 27).to(device) # required to return the attention weights\n",
    "    predictions = torch.zeros(22-1, 1).to(device)\n",
    "    with torch.no_grad():\n",
    "      for j,(x,y) in enumerate(loader):\n",
    "        loss=0\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        x = x.T\n",
    "        y = y.T\n",
    "        seq_len = len(y)\n",
    "        encoder_hidden=encoder.initHidden(batch_size=x.shape[1])\n",
    "        encoder_output,encoder_hidden = encoder(x,encoder_hidden)\n",
    "        \n",
    "        \n",
    "        decoder_input =y[0]\n",
    "        \n",
    "        # Handle different numbers of layers in the encoder and decoder\n",
    "        if num_layers_encoder != num_layers_decoder:\n",
    "            if num_layers_encoder < num_layers_decoder:\n",
    "                remaining_layers = num_layers_decoder - num_layers_encoder\n",
    "\n",
    "                # Copy all encoder hidden layers and then repeat the top layer\n",
    "                if cell_type == \"LSTM\":\n",
    "                    top_layer_hidden = (encoder_hidden[0][-1].unsqueeze(0), encoder_hidden[1][-1].unsqueeze(0))\n",
    "                    extra_hidden = (top_layer_hidden[0].repeat(remaining_layers, 1, 1), top_layer_hidden[1].repeat(remaining_layers, 1, 1))\n",
    "                    decoder_hidden = (torch.cat((encoder_hidden[0], extra_hidden[0]), dim=0), torch.cat((encoder_hidden[1], extra_hidden[1]), dim=0))\n",
    "                else:\n",
    "                    top_layer_hidden = encoder_hidden[-1].unsqueeze(0) #top_layer_hidden shape (1, batch_size, hidden_size)\n",
    "                    extra_hidden = top_layer_hidden.repeat(remaining_layers, 1, 1)\n",
    "                    decoder_hidden = torch.cat((encoder_hidden, extra_hidden), dim=0)\n",
    "\n",
    "            else:\n",
    "                # Slice the hidden states of the encoder to match the decoder layers\n",
    "                if cell_type == \"LSTM\":\n",
    "                    decoder_hidden = (encoder_hidden[0][-num_layers_decoder:], encoder_hidden[1][-num_layers_decoder:])\n",
    "                else :\n",
    "                    decoder_hidden = encoder_hidden[-num_layers_decoder:]\n",
    "        else:\n",
    "            decoder_hidden = encoder_hidden\n",
    "\n",
    "        pred=torch.zeros(len(y)-1, batch_size).to(device)\n",
    "        atten_weight_default = torch.zeros(batch_size,1, 27).to(device)\n",
    "        for k in range(1,len(y)):\n",
    "          if attention == \"Yes\":\n",
    "              \n",
    "              decoder_output, decoder_hidden, atten_weight = decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "              atten_weight_default = torch.cat((atten_weight_default, atten_weight), dim = 1)\n",
    "          else:\n",
    "              decoder_output, decoder_hidden= decoder(decoder_input, decoder_hidden)\n",
    "          max_prob, index = decoder_output.topk(1) # max_prob shape (1, batch_size, 1)\n",
    "          decoder_output = torch.squeeze(decoder_output)\n",
    "          loss += loss_fun(decoder_output, y[k].long())\n",
    "          pred[k-1]= torch.squeeze(index)\n",
    "          decoder_input = index\n",
    "        if attention == \"Yes\":\n",
    "            atten_weights = torch.cat((atten_weights, atten_weight_default[:, 1:, :]), dim = 0)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        correct += count_exact_matches(pred.T,y[1:,:].T)\n",
    "        predictions = torch.cat((predictions, pred), dim=1)\n",
    "\n",
    "        \n",
    "    avg_loss = running_loss / (len(data) * seq_len)\n",
    "    print(\"correct =\", correct)\n",
    "    avg_acc = 100 * (correct / (len(data)))\n",
    "    if attention == \"Yes\":\n",
    "        return avg_loss, avg_acc, predictions, atten_weights[1:, :, :]\n",
    "    else:\n",
    "        return avg_loss, avg_acc, predictions\n",
    "            \n",
    "   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T07:03:57.648900Z",
     "iopub.status.busy": "2025-05-19T07:03:57.648644Z",
     "iopub.status.idle": "2025-05-19T07:03:57.666549Z",
     "shell.execute_reply": "2025-05-19T07:03:57.665879Z",
     "shell.execute_reply.started": "2025-05-19T07:03:57.648883Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(sweeps = True, test = False):\n",
    "\n",
    "    if sweeps == False: \n",
    "        configs = config_defaults  # use the default configuration which has the best hyperparameters\n",
    "    else:\n",
    "        wandb.init(config= config_defaults, project='DL_assign_3')   # if not test then run wandb sweeps\n",
    "        configs=wandb.config\n",
    "    \n",
    "    # Set batch_size as a module attribute\n",
    "    global batch_size\n",
    "    batch_size = configs['batch_size']\n",
    "       \n",
    "\n",
    "    learn_rate = configs['learn_rate']\n",
    "    batch_size = configs['batch_size']\n",
    "    hidden_size = configs['hidden_size']\n",
    "    embedding_size = configs['embedding_size']\n",
    "    num_layers_encoder = configs['num_layers_encoder']\n",
    "    num_layers_decoder = configs['num_layers_decoder']\n",
    "    cell_type = configs['cell_type']\n",
    "    bidirectional = configs['bidirectional']\n",
    "    dropout = configs['dropout']\n",
    "    teach_ratio = configs['teach_ratio']\n",
    "    epochs = configs['epochs']\n",
    "    attention = configs['attention']\n",
    "\n",
    "    if sweeps:\n",
    "       wandb.run.name='hidden_'+str(hidden_size)+'_batch_'+str(batch_size)+'_embed_size_'+str(embedding_size)+'_dropout_'+str(dropout)+'_cell_'+str(cell_type)\n",
    "\n",
    "    input_len = ipLang.n_chars\n",
    "    output_len = opLang.n_chars\n",
    "    \n",
    "    encoder = EncoderRNN(input_len, hidden_size, embedding_size, \n",
    "                 num_layers_encoder, cell_type,\n",
    "                  bidirectional, dropout, batch_size)\n",
    "    \n",
    "    if attention ==\"Yes\":\n",
    "        decoder = AttentionDecoderRNN(hidden_size, output_len, embedding_size, num_layers_decoder, \n",
    "                 cell_type, dropout, batch_size, 27)\n",
    "    else:\n",
    "        decoder = DecoderRNN(hidden_size, output_len, embedding_size, num_layers_decoder, \n",
    "                 cell_type, dropout, batch_size)#dropout not used\n",
    "    \n",
    "    train_loader = DataLoader(trainData, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(valData, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    encoder_optimizer=optim.Adam(encoder.parameters(),learn_rate)\n",
    "    decoder_optimizer=optim.Adam(decoder.parameters(),learn_rate)\n",
    "    loss_fun=nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "    seq_len = 0\n",
    "\n",
    "    # Initialize variables for early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 5\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    for i in range(epochs):\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        train_correct = 0\n",
    "\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "\n",
    "        for j,(train_x,train_y) in enumerate(train_loader):\n",
    "            train_x = train_x.to(device)\n",
    "            train_y = train_y.to(device)\n",
    "\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "\n",
    "            train_x=train_x.T\n",
    "            train_y=train_y.T\n",
    "            seq_len = len(train_y)\n",
    "            encoder_hidden=encoder.initHidden(batch_size=train_x.shape[1])\n",
    "            encoder_output,encoder_hidden = encoder(train_x,encoder_hidden)\n",
    "            # encoder_hidden shape (num_layers, batch_size, hidden_size)\n",
    "            \n",
    "            \n",
    "            # lets move to the decoder\n",
    "            decoder_input = train_y[0] # shape (1, batch_size)\n",
    "           \n",
    "            # Handle different numbers of layers in the encoder and decoder\n",
    "            if num_layers_encoder != num_layers_decoder:\n",
    "                if num_layers_encoder < num_layers_decoder:\n",
    "                    remaining_layers = num_layers_decoder - num_layers_encoder\n",
    "                    # Copy all encoder hidden layers and then repeat the top layer\n",
    "                    if cell_type == \"LSTM\":\n",
    "                        top_layer_hidden = (encoder_hidden[0][-1].unsqueeze(0), encoder_hidden[1][-1].unsqueeze(0))\n",
    "                        extra_hidden = (top_layer_hidden[0].repeat(remaining_layers, 1, 1), top_layer_hidden[1].repeat(remaining_layers, 1, 1))\n",
    "                        decoder_hidden = (torch.cat((encoder_hidden[0], extra_hidden[0]), dim=0), torch.cat((encoder_hidden[1], extra_hidden[1]), dim=0))\n",
    "                    else:\n",
    "                        top_layer_hidden = encoder_hidden[-1].unsqueeze(0) #top_layer_hidden shape (1, batch_size, hidden_size)\n",
    "                        extra_hidden = top_layer_hidden.repeat(remaining_layers, 1, 1)\n",
    "                        decoder_hidden = torch.cat((encoder_hidden, extra_hidden), dim=0)\n",
    "  \n",
    "                else:\n",
    "                    # Slice the hidden states of the encoder to match the decoder layers\n",
    "                    if cell_type == \"LSTM\":\n",
    "                        decoder_hidden = (encoder_hidden[0][-num_layers_decoder:], encoder_hidden[1][-num_layers_decoder:])\n",
    "                    else :\n",
    "                        decoder_hidden = encoder_hidden[-num_layers_decoder:]\n",
    "            else:\n",
    "                decoder_hidden = encoder_hidden\n",
    "            \n",
    "            loss = 0\n",
    "            correct = 0\n",
    "           \n",
    "            for k in range(0, len(train_y)-1):\n",
    "                \n",
    "                if attention == \"Yes\":\n",
    "                    decoder_output, decoder_hidden, atten_weights = decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "                else:\n",
    "                    decoder_output, decoder_hidden= decoder(decoder_input, decoder_hidden) # decoder_output shape (1, batch_size, output_size)\n",
    "\n",
    "                max_prob, index = decoder_output.topk(1) # max_prob shape (1, batch_size, 1)\n",
    "                index = torch.squeeze(index) # shape (batch_size)\n",
    "                decoder_output = torch.squeeze(decoder_output)\n",
    "                loss += loss_fun(decoder_output, train_y[k+1].long())\n",
    "                \n",
    "                correct += (index == train_y[k+1]).sum().item()\n",
    "\n",
    "                # Apply teacher forcing\n",
    "                use_teacher_forcing = True if random.random() < teach_ratio else False\n",
    "\n",
    "                if use_teacher_forcing:\n",
    "                    decoder_input = train_y[k+1]\n",
    "                \n",
    "                else:\n",
    "                    decoder_input = index\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            train_correct += correct\n",
    "            loss.backward()\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "        \n",
    "\n",
    "        # find train loss and accuracy and print + log to wandb\n",
    "        if attention == \"Yes\":\n",
    "            _, train_accuracy,_, _ = evaluate(trainData,encoder, decoder,output_len,batch_size,hidden_size,num_layers_encoder,num_layers_decoder, cell_type, attention)\n",
    "        else:\n",
    "            _, train_accuracy,_= evaluate(trainData,encoder, decoder,output_len,batch_size,hidden_size,num_layers_encoder,num_layers_decoder, cell_type, attention)\n",
    "        \n",
    "        print(f\"epoch {i}, training loss {running_loss/(len(trainData)* seq_len)}, training accuracy {train_accuracy}\")\n",
    "        if sweeps:\n",
    "            wandb.log({\"epoch\": i, \"train_loss\": running_loss/(len(trainData)* seq_len), \"train_accuracy\": train_accuracy})\n",
    "        \n",
    "        # # find validation loss and accuracy and print + log to wandb\n",
    "        if attention == \"Yes\":\n",
    "            val_loss, val_accuracy,_, _ = evaluate(valData,encoder, decoder,output_len,batch_size,hidden_size,num_layers_encoder,num_layers_decoder, cell_type, attention)\n",
    "        else:\n",
    "            val_loss, val_accuracy,_ = evaluate(valData,encoder, decoder,output_len,batch_size,hidden_size,num_layers_encoder,num_layers_decoder, cell_type, attention)\n",
    "        \n",
    "        print(f\"epoch {i}, validation loss {val_loss}, validation accuracy {val_accuracy}\")\n",
    "        if sweeps:\n",
    "            wandb.log({\"val_loss\": val_loss, \"val_accuracy\": val_accuracy})\n",
    "\n",
    "        # Check for early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_without_improvement = 0\n",
    "            # Save the model weights\n",
    "            torch.save(encoder.state_dict(), 'best_encoder.pt')\n",
    "            torch.save(decoder.state_dict(), 'best_decoder.pt')\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(\"Early stopping triggered. No improvement in validation loss.\")\n",
    "                break\n",
    "        \n",
    "    \n",
    "    # if testing mode is on print the test accuracy \n",
    "    if test:\n",
    "        # Load the best model weights\n",
    "        encoder.load_state_dict(torch.load('best_encoder.pt'))\n",
    "        decoder.load_state_dict(torch.load('best_decoder.pt'))\n",
    "        if attention == \"Yes\":\n",
    "            _, test_accuracy, pred, atten_weights = evaluate(testData,encoder, decoder,output_len,batch_size,hidden_size,num_layers_encoder,num_layers_decoder, cell_type, attention)\n",
    "        else:\n",
    "            _, test_accuracy, pred = evaluate(testData,encoder, decoder,output_len,batch_size,hidden_size,num_layers_encoder,num_layers_decoder, cell_type, attention)\n",
    "        print(f\"test accuracy {test_accuracy}\")\n",
    "\n",
    "    if attention == \"Yes\":\n",
    "        return pred, atten_weights\n",
    "    else:\n",
    "        return pred\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T07:04:06.351487Z",
     "iopub.status.busy": "2025-05-19T07:04:06.351230Z",
     "iopub.status.idle": "2025-05-19T07:04:06.357985Z",
     "shell.execute_reply": "2025-05-19T07:04:06.357367Z",
     "shell.execute_reply.started": "2025-05-19T07:04:06.351467Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def translate_prediction(input_dict , input, output_dict, pred,target):\n",
    "    \n",
    "    '''pred in shape of seq_len-1 * dataset_size\n",
    "       target in shape datasize * seq_len-1\n",
    "    '''\n",
    "    pred = pred.T # shape datasize * seq len-1\n",
    "    pred = pred[1:, :-1] # ignore last index of each row\n",
    "    input = input[:, :-1] # ignore  last index of each row\n",
    "    target = target[:, 1:-1] # ignore last index of each row\n",
    "    print(f\"pred shape {pred.shape}, input shape {input.shape}, target shape {target.shape}\")\n",
    "    predictions = [] \n",
    "    Input = [] \n",
    "    Target = []\n",
    "    for i in range(len(pred)):\n",
    "        \n",
    "        pred_word=\"\"\n",
    "        input_word=\"\"\n",
    "        target_word = \"\"\n",
    "\n",
    "        for j in range(pred.shape[1]):\n",
    "\n",
    "            # Ignore padding\n",
    "            if(target[i][j].item() != 0):\n",
    "              \n",
    "              pred_word += output_dict[pred[i][j].item()]\n",
    "              target_word += output_dict[target[i][j].item()]\n",
    "                    \n",
    "        for j in range(input.shape[1]):\n",
    "            \n",
    "               if(input[i][j].item()!=0):\n",
    "                    \n",
    "                    input_word += input_dict[input[i][j].item()]   \n",
    "\n",
    "        # Append words in respective List\n",
    "        \n",
    "        predictions.append(pred_word)\n",
    "        Input.append(input_word)         \n",
    "        Target.append(target_word)   \n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\"input\": Input, \"predicted\": predictions,\"Actual\":Target})\n",
    "    return df\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T07:04:13.795013Z",
     "iopub.status.busy": "2025-05-19T07:04:13.794261Z",
     "iopub.status.idle": "2025-05-19T07:04:13.801456Z",
     "shell.execute_reply": "2025-05-19T07:04:13.800582Z",
     "shell.execute_reply.started": "2025-05-19T07:04:13.794980Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "  'name': 'sweepDL',  \n",
    "  'method': 'bayes',\n",
    "  'metric': {\n",
    "        'name': 'val_accuracy',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "  'parameters': {\n",
    "        \n",
    "        'learn_rate': {\n",
    "            'values': [0.01, 0.001, 0.001]\n",
    "        },\n",
    "        'embedding_size': {\n",
    "            'values': [32, 64, 128, 256, 512, 1024]\n",
    "        },\n",
    "        'batch_size':{\n",
    "            'values':[16, 32, 64, 128, 256]\n",
    "        },\n",
    "        'hidden_size':{\n",
    "            'values':[32, 64, 128, 256, 512, 1024]\n",
    "        },\n",
    "        'teach_ratio':{\n",
    "            'values':[0.4, 0.5, 0.6]\n",
    "        },\n",
    "        'dropout':{\n",
    "            'values':[0, 0.2, 0.4]\n",
    "        },\n",
    "        'cell_type':{\n",
    "            'values':[\"RNN\", \"LSTM\", \"GRU\"]\n",
    "        },\n",
    "        'bidirectional':{\n",
    "            'values' : [\"Yes\",\"No\"]\n",
    "        },\n",
    "        'num_layers_decoder':{\n",
    "            'values': [1,2, 3, 4]\n",
    "        },\n",
    "        'num_layers_encoder':{\n",
    "            'values': [1,2,3,4]\n",
    "        },\n",
    "        'epochs':{\n",
    "            'values': [10, 15, 20, 25, 30]\n",
    "        },\n",
    "        'attention':{\n",
    "            'values': [\"Yes\"]\n",
    "        }\n",
    "           \n",
    "    }\n",
    "}\n",
    "config_defaults={\n",
    "    'learn_rate' : 0.001,\n",
    "    'embedding_size': 32,\n",
    "    'batch_size': 256,\n",
    "    'hidden_size' : 1024,\n",
    "    'num_layers_encoder': 3,\n",
    "    'num_layers_decoder': 3,\n",
    "    'bidirectional': 'No',\n",
    "    'cell_type': \"LSTM\",\n",
    "    'teach_ratio': 0.6,\n",
    "    'dropout': 0.4,\n",
    "    'epochs': 15,\n",
    "    'attention': \"No\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T07:04:18.529651Z",
     "iopub.status.busy": "2025-05-19T07:04:18.529356Z",
     "iopub.status.idle": "2025-05-19T07:04:24.819050Z",
     "shell.execute_reply": "2025-05-19T07:04:24.818371Z",
     "shell.execute_reply.started": "2025-05-19T07:04:18.529629Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mma23c047\u001b[0m (\u001b[33mma23c047-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key =\"f15dba29e56f32e9c31d598bce5bc7a3c76de62e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T07:05:36.796349Z",
     "iopub.status.busy": "2025-05-19T07:05:36.795837Z",
     "iopub.status.idle": "2025-05-19T07:07:28.174513Z",
     "shell.execute_reply": "2025-05-19T07:07:28.173504Z",
     "shell.execute_reply.started": "2025-05-19T07:05:36.796329Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: bm3hff42\n",
      "Sweep URL: https://wandb.ai/ma23c047-indian-institute-of-technology-madras/DA6401_A3/sweeps/bm3hff42\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden[0] size (3, 172, 1024), got [3, 256, 1024]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35/695789812.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run sweep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msweep_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweep_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"DA6401_A3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweep_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweeps\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_35/1713152420.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(sweeps, test)\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_layers_encoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_layers_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_layers_encoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_layers_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"epoch {i}, training loss {running_loss/(len(trainData)* seq_len)}, training accuracy {train_accuracy}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_35/3841131653.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(data, encoder, decoder, output_size, batch_size, hidden_size, num_layers_encoder, num_layers_decoder, cell_type, attention)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitHidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_35/3898396692.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# No need to reshape since embedding output is already (seq_len, batch_size, embedding_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1118\u001b[0m                 \u001b[0;31m# Each batch of the hidden state should match the input sequence that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m                 \u001b[0;31m# the user believes he/she is passing in.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m                 \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m   1001\u001b[0m     ):\n\u001b[1;32m   1002\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m         self.check_hidden_size(\n\u001b[0m\u001b[1;32m   1004\u001b[0m             \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    345\u001b[0m     ) -> None:\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_weights_have_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden[0] size (3, 172, 1024), got [3, 256, 1024]"
     ]
    }
   ],
   "source": [
    "# Run sweep\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"DA6401_A3\")\n",
    "wandb.agent(sweep_id, function=train, count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7437239,
     "sourceId": 11837623,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
