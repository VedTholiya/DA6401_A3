{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-18T23:36:57.554896Z",
     "iopub.status.busy": "2025-05-18T23:36:57.554578Z",
     "iopub.status.idle": "2025-05-18T23:36:57.559564Z",
     "shell.execute_reply": "2025-05-18T23:36:57.558889Z",
     "shell.execute_reply.started": "2025-05-18T23:36:57.554857Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T23:36:57.561051Z",
     "iopub.status.busy": "2025-05-18T23:36:57.560860Z",
     "iopub.status.idle": "2025-05-18T23:36:57.582496Z",
     "shell.execute_reply": "2025-05-18T23:36:57.581956Z",
     "shell.execute_reply.started": "2025-05-18T23:36:57.561038Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T23:36:57.583251Z",
     "iopub.status.busy": "2025-05-18T23:36:57.583087Z",
     "iopub.status.idle": "2025-05-18T23:36:57.598556Z",
     "shell.execute_reply": "2025-05-18T23:36:57.598002Z",
     "shell.execute_reply.started": "2025-05-18T23:36:57.583239Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.char2index = {'#': 0, '$': 1, '^': 2}  # # for padding, $ for unknown, ^ for start\n",
    "        self.char2count = {'#': 1, '$': 1, '^': 1}\n",
    "        self.index2char = {0: '#', 1: '$', 2: '^'}\n",
    "        self.n_chars = 3  # Count\n",
    "        self.data = {}\n",
    "    \n",
    "    def addWord(self, word):\n",
    "        for char in word:\n",
    "            self.addChar(char)\n",
    "\n",
    "    def addChar(self, char):\n",
    "        if char not in self.char2index:\n",
    "            self.char2index[char] = self.n_chars\n",
    "            self.char2count[char] = 1\n",
    "            self.index2char[self.n_chars] = char\n",
    "            self.n_chars += 1\n",
    "        else:\n",
    "            self.char2count[char] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T23:36:57.599472Z",
     "iopub.status.busy": "2025-05-18T23:36:57.599245Z",
     "iopub.status.idle": "2025-05-18T23:36:57.613757Z",
     "shell.execute_reply": "2025-05-18T23:36:57.613257Z",
     "shell.execute_reply.started": "2025-05-18T23:36:57.599454Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Return max length of input and output words\n",
    "def maxLength(data):\n",
    "    ip_mlen, op_mlen = 0, 0\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        input = data[0][i]\n",
    "        output = data[1][i]\n",
    "        if(len(input) > ip_mlen):\n",
    "            ip_mlen = len(input)\n",
    "        if(len(output) > op_mlen):\n",
    "            op_mlen = len(output)\n",
    "\n",
    "    return ip_mlen, op_mlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T23:36:57.615499Z",
     "iopub.status.busy": "2025-05-18T23:36:57.615127Z",
     "iopub.status.idle": "2025-05-18T23:36:57.629452Z",
     "shell.execute_reply": "2025-05-18T23:36:57.628960Z",
     "shell.execute_reply.started": "2025-05-18T23:36:57.615484Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T23:36:57.630300Z",
     "iopub.status.busy": "2025-05-18T23:36:57.630120Z",
     "iopub.status.idle": "2025-05-18T23:36:57.648329Z",
     "shell.execute_reply": "2025-05-18T23:36:57.647757Z",
     "shell.execute_reply.started": "2025-05-18T23:36:57.630286Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess(data, input_lang, output_lang):\n",
    "    maxlenInput, maxlenOutput = maxLength(data)\n",
    "    # We use maxlenInput as 26 since it is the maximum of all input len\n",
    "    maxlenInput = 26\n",
    "    input = numpy.zeros((len(data), maxlenInput + 1))\n",
    "    output = numpy.zeros((len(data), maxlenOutput + 2))\n",
    "    maxlenInput, maxlenOutput = maxLength(data)\n",
    "    unknown = input_lang.char2index['$']\n",
    "    for i in range(len(data)):\n",
    "        op = '^' + data[1][i]\n",
    "        ip = data[0][i].ljust(maxlenInput + 1, '#')\n",
    "        op = op.ljust(maxlenOutput + 2, '#')\n",
    "\n",
    "        for index, char in enumerate(ip):\n",
    "            if input_lang.char2index.get(char) is not None:\n",
    "                input[i][index] = input_lang.char2index[char]\n",
    "            else:\n",
    "                input[i][index] = unknown\n",
    "\n",
    "        for index, char in enumerate(op):\n",
    "            if output_lang.char2index.get(char) is not None:\n",
    "                output[i][index] = output_lang.char2index[char]\n",
    "            else:\n",
    "                output[i][index] = unknown \n",
    "\n",
    "    print(input.shape)\n",
    "    print(output.shape)\n",
    "\n",
    "    return TensorDataset(torch.from_numpy(input), torch.from_numpy(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T23:36:57.649294Z",
     "iopub.status.busy": "2025-05-18T23:36:57.649070Z",
     "iopub.status.idle": "2025-05-18T23:36:57.672138Z",
     "shell.execute_reply": "2025-05-18T23:36:57.671653Z",
     "shell.execute_reply.started": "2025-05-18T23:36:57.649280Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def loadData(lang):\n",
    "    train_df = pd.read_csv(f\"{DATA_PATH}/{lang}/lexicons/{lang}.translit.sampled.train.tsv\", sep='\\t', header=None)\n",
    "    val_df = pd.read_csv(f\"{DATA_PATH}/{lang}/lexicons/{lang}.translit.sampled.dev.tsv\", sep='\\t', header=None)\n",
    "    test_df = pd.read_csv(f\"{DATA_PATH}/{lang}/lexicons/{lang}.translit.sampled.test.tsv\", sep='\\t', header=None)\n",
    "    \n",
    "    # Replace NaN values with empty strings and ensure all values are strings\n",
    "    train_df = train_df.fillna('').astype(str)\n",
    "    val_df = val_df.fillna('').astype(str)\n",
    "    test_df = test_df.fillna('').astype(str)\n",
    "    \n",
    "    input_lang = Lang('eng')\n",
    "    output_lang = Lang(lang)\n",
    "    \n",
    "    # Add the words to the respective languages\n",
    "    for i in range(len(train_df)):\n",
    "        input_lang.addWord(train_df[0][i])\n",
    "        output_lang.addWord(train_df[1][i])\n",
    "\n",
    "    trainDataset = preprocess(train_df, input_lang, output_lang)\n",
    "    testDataset = preprocess(test_df, input_lang, output_lang)\n",
    "    valDataset = preprocess(val_df, input_lang, output_lang)\n",
    "\n",
    "    return trainDataset, testDataset, valDataset, input_lang, output_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T23:36:57.672936Z",
     "iopub.status.busy": "2025-05-18T23:36:57.672703Z",
     "iopub.status.idle": "2025-05-18T23:36:57.694296Z",
     "shell.execute_reply": "2025-05-18T23:36:57.693825Z",
     "shell.execute_reply.started": "2025-05-18T23:36:57.672917Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH  = r\"C:\\Users\\vedpr\\Downloads\\dakshina_dataset_v1.0\\dakshina_dataset_v1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T23:36:57.695025Z",
     "iopub.status.busy": "2025-05-18T23:36:57.694866Z",
     "iopub.status.idle": "2025-05-18T23:37:00.041978Z",
     "shell.execute_reply": "2025-05-18T23:37:00.041391Z",
     "shell.execute_reply.started": "2025-05-18T23:36:57.695013Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44204, 27)\n",
      "(44204, 22)\n",
      "(4502, 27)\n",
      "(4502, 18)\n",
      "(4358, 27)\n",
      "(4358, 20)\n"
     ]
    }
   ],
   "source": [
    "trainData, testData, valData, ipLang, opLang = loadData('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T23:44:58.525455Z",
     "iopub.status.busy": "2025-05-18T23:44:58.524905Z",
     "iopub.status.idle": "2025-05-18T23:44:58.535337Z",
     "shell.execute_reply": "2025-05-18T23:44:58.534777Z",
     "shell.execute_reply.started": "2025-05-18T23:44:58.525426Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, embedding_size, # input_size is size of input language dictionary\n",
    "                 num_layers, cell_type,\n",
    "                  bidirectional, dropout, batch_size) :\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size  # size of an hidden state representation\n",
    "        self.num_layers = num_layers   \n",
    "        self.bidirectional = True if bidirectional == 'Yes' else False\n",
    "        self.batch_size = batch_size\n",
    "        self.cell_type = cell_type\n",
    "        self.embedding_size=embedding_size\n",
    "\n",
    "        # this adds the embedding layer\n",
    "        self.embedding = nn.Embedding(num_embeddings=input_size,embedding_dim= embedding_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # this adds the Neural Network layer for the encoder\n",
    "        if self.cell_type == \"GRU\":\n",
    "            self.rnn = nn.GRU(embedding_size, hidden_size, num_layers=num_layers, bidirectional=self.bidirectional, dropout=dropout)\n",
    "        elif self.cell_type == \"LSTM\":\n",
    "            self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers=num_layers, bidirectional=self.bidirectional, dropout=dropout)\n",
    "        else:\n",
    "            self.rnn = nn.RNN(embedding_size, hidden_size, num_layers=num_layers, bidirectional=self.bidirectional, dropout=dropout)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "    # input shape: (seq_len, batch_size)\n",
    "        embedded = self.embedding(input.long())  # shape: (seq_len, batch_size, embedding_size)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        # No need to reshape since embedding output is already (seq_len, batch_size, embedding_size)\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        \n",
    "        if self.bidirectional:\n",
    "            if self.cell_type == \"LSTM\":\n",
    "                hidden_state = hidden[0].view(2, self.num_layers, hidden_state.shape[2], self.hidden_size)\n",
    "                cell_state = hidden[1].view(2, self.num_layers, cell_state.shape[2], self.hidden_size)\n",
    "                hidden = (torch.add(hidden_state[0], hidden_state[1]) / 2, torch.add(cell_state[0], cell_state[1]) / 2)\n",
    "            else:\n",
    "                hidden = hidden.view(2, self.num_layers, hidden.shape[2], self.hidden_size)\n",
    "                hidden = torch.add(hidden[0], hidden[1]) / 2\n",
    "            \n",
    "            split_tensor = torch.split(output, self.hidden_size, dim=-1)\n",
    "            output = torch.add(split_tensor[0], split_tensor[1]) / 2\n",
    "    \n",
    "        return output, hidden\n",
    "\n",
    "    # initializing the initial hidden state for the encoder\n",
    "    def initHidden(self, batch_size):\n",
    "        num_directions = 2 if self.bidirectional else 1\n",
    "        if self.cell_type == \"LSTM\":\n",
    "            return (\n",
    "                torch.zeros(self.num_layers * num_directions, batch_size, self.hidden_size, device=device),\n",
    "                torch.zeros(self.num_layers * num_directions, batch_size, self.hidden_size, device=device)\n",
    "            )\n",
    "        else:\n",
    "            return torch.zeros(self.num_layers * num_directions, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T23:37:00.054526Z",
     "iopub.status.busy": "2025-05-18T23:37:00.054084Z",
     "iopub.status.idle": "2025-05-18T23:37:00.077304Z",
     "shell.execute_reply": "2025-05-18T23:37:00.076812Z",
     "shell.execute_reply.started": "2025-05-18T23:37:00.054498Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, embedding_size, num_layers, # output size is the size of output language dictionary\n",
    "                 cell_type, dropout, batch_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.cell_type = cell_type.lower()\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding_size=embedding_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
    "        # self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        if self.cell_type == \"gru\":\n",
    "            self.rnn = nn.GRU(embedding_size, hidden_size, num_layers=num_layers)\n",
    "        elif self.cell_type == \"lstm\":\n",
    "            self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers=num_layers)\n",
    "        else:\n",
    "            self.rnn = nn.RNN(embedding_size, hidden_size, num_layers=num_layers)\n",
    "\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, input, hidden): # input shape (1, batch_size)\n",
    "        embedded = self.embedding(input.long()).view(-1, self.batch_size, self.embedding_size)\n",
    "        # # shape (1, batch_size, embedding_size)\n",
    "        output = F.relu(embedded)\n",
    "        output, hidden = self.rnn(output, hidden) # output shape (1, batch_size, hidden_size)\n",
    "        output = self.softmax(self.out(output)) # shape (1, batch_size, output_size)\n",
    "        return output, hidden\n",
    "\n",
    "    # not needed since hidden will be provided by the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T23:37:00.078614Z",
     "iopub.status.busy": "2025-05-18T23:37:00.078018Z",
     "iopub.status.idle": "2025-05-18T23:37:00.102077Z",
     "shell.execute_reply": "2025-05-18T23:37:00.101554Z",
     "shell.execute_reply.started": "2025-05-18T23:37:00.078596Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AttentionDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, embedding_size, num_layers,\n",
    "                 cell_type, dropout, batch_size, max_length):\n",
    "        super(AttentionDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.cell_type = cell_type\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.max_length = max_length\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
    "        self.dropout = nn.Dropout(self.dropout)\n",
    "        self.attention = nn.Linear(hidden_size + embedding_size, self.max_length)\n",
    "        self.attention_combine = nn.Linear(hidden_size + embedding_size, hidden_size)\n",
    "\n",
    "        if self.cell_type == \"GRU\":\n",
    "            self.rnn = nn.GRU(hidden_size, hidden_size, num_layers=num_layers)\n",
    "        elif self.cell_type == \"LSTM\":\n",
    "            self.rnn = nn.LSTM(hidden_size, hidden_size, num_layers=num_layers)\n",
    "        else:\n",
    "            self.rnn = nn.RNN(hidden_size, hidden_size, num_layers=num_layers)\n",
    "\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs): #input shape (1, batch_size)\n",
    "        embedded = self.embedding(input.long()).view(-1, self.batch_size, self.embedding_size) \n",
    "        # embedded shape (1, batch_size, embedding_size)\n",
    "        embedded = F.relu(embedded)\n",
    "\n",
    "        # Compute attention scores\n",
    "        if self.cell_type == \"LSTM\":\n",
    "            attn_hidden = torch.mean(hidden[0], dim=0)\n",
    "        else:\n",
    "            attn_hidden = torch.mean(hidden, dim = 0)\n",
    "        attn_scores = self.attention(torch.cat((embedded, attn_hidden.unsqueeze(0)), dim=2)) # attn_scores shape (1, batch_size, max_length)\n",
    "        \n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)  # attn_scores shape (1, 16, 25)\n",
    "        \n",
    "\n",
    "        # Apply attention weights to encoder outputs\n",
    "        attn_applied = torch.bmm(attn_weights.transpose(0, 1), encoder_outputs.transpose(0, 1))\n",
    "        \n",
    "        # Combine attention output and embedded input\n",
    "        combined = torch.cat((embedded, attn_applied.transpose(0, 1)), dim=2)\n",
    "        combined = self.attention_combine(combined)\n",
    "        combined = F.relu(combined) # shape (1, batch_size, hidden_size)\n",
    "\n",
    "        # Run through the RNN\n",
    "        output, hidden = self.rnn(combined, hidden)\n",
    "        # output shape: (1, batch_size, hidden_size)\n",
    "\n",
    "        # Pass through linear layer and softmax activation\n",
    "        output = self.out(output)  # shape: (1, batch_size, output_size)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden, attn_weights.transpose(0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T23:37:00.102867Z",
     "iopub.status.busy": "2025-05-18T23:37:00.102619Z",
     "iopub.status.idle": "2025-05-18T23:37:00.123580Z",
     "shell.execute_reply": "2025-05-18T23:37:00.123081Z",
     "shell.execute_reply.started": "2025-05-18T23:37:00.102851Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def count_exact_matches(pred, target):\n",
    "    \"\"\"\n",
    "    Counts the number of rows in preds tensor that match exactly with each row in y tensor.\n",
    "    pred: tensor of shape (batch_size, seq_len-1)\n",
    "    y: tensor of shape (batch_size, seq_len-1)\n",
    "    \"\"\"\n",
    "    \n",
    "    count=0;\n",
    "    for i in range(pred.shape[0]):\n",
    "      flag = True\n",
    "      for j in range(pred.shape[1]):\n",
    "        if(target[i][j]!=pred[i][j]):\n",
    "          flag=False\n",
    "          break;\n",
    "         \n",
    "      if(flag):\n",
    "        count+=1;\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T23:37:00.124399Z",
     "iopub.status.busy": "2025-05-18T23:37:00.124171Z",
     "iopub.status.idle": "2025-05-18T23:37:00.141011Z",
     "shell.execute_reply": "2025-05-18T23:37:00.140491Z",
     "shell.execute_reply.started": "2025-05-18T23:37:00.124384Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(data,encoder, decoder,output_size,batch_size,hidden_size,num_layers_encoder,num_layers_decoder, cell_type, attention):\n",
    "    \n",
    "\n",
    "\n",
    "    running_loss = 0\n",
    "    correct =0\n",
    "    \n",
    "    loader = DataLoader(data, batch_size=batch_size)\n",
    "    loss_fun = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "    seq_len = 0\n",
    "\n",
    "    atten_weights = torch.zeros(1,21, 27).to(device) # required to return the attention weights\n",
    "    predictions = torch.zeros(22-1, 1).to(device)\n",
    "    with torch.no_grad():\n",
    "      for j,(x,y) in enumerate(loader):\n",
    "        loss=0\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        x = x.T\n",
    "        y = y.T\n",
    "        seq_len = len(y)\n",
    "        \n",
    "        encoder_hidden=encoder.initHidden(x.shape[1])\n",
    "        encoder_output,encoder_hidden = encoder(x,encoder_hidden)\n",
    "        \n",
    "        \n",
    "        decoder_input =y[0]\n",
    "        \n",
    "        # Handle different numbers of layers in the encoder and decoder\n",
    "        if num_layers_encoder != num_layers_decoder:\n",
    "            if num_layers_encoder < num_layers_decoder:\n",
    "                remaining_layers = num_layers_decoder - num_layers_encoder\n",
    "\n",
    "                # Copy all encoder hidden layers and then repeat the top layer\n",
    "                if cell_type == \"LSTM\":\n",
    "                    top_layer_hidden = (encoder_hidden[0][-1].unsqueeze(0), encoder_hidden[1][-1].unsqueeze(0))\n",
    "                    extra_hidden = (top_layer_hidden[0].repeat(remaining_layers, 1, 1), top_layer_hidden[1].repeat(remaining_layers, 1, 1))\n",
    "                    decoder_hidden = (torch.cat((encoder_hidden[0], extra_hidden[0]), dim=0), torch.cat((encoder_hidden[1], extra_hidden[1]), dim=0))\n",
    "                else:\n",
    "                    top_layer_hidden = encoder_hidden[-1].unsqueeze(0) #top_layer_hidden shape (1, batch_size, hidden_size)\n",
    "                    extra_hidden = top_layer_hidden.repeat(remaining_layers, 1, 1)\n",
    "                    decoder_hidden = torch.cat((encoder_hidden, extra_hidden), dim=0)\n",
    "\n",
    "            else:\n",
    "                # Slice the hidden states of the encoder to match the decoder layers\n",
    "                if cell_type == \"LSTM\":\n",
    "                    decoder_hidden = (encoder_hidden[0][-num_layers_decoder:], encoder_hidden[1][-num_layers_decoder:])\n",
    "                else :\n",
    "                    decoder_hidden = encoder_hidden[-num_layers_decoder:]\n",
    "        else:\n",
    "            decoder_hidden = encoder_hidden\n",
    "\n",
    "        pred=torch.zeros(len(y)-1, batch_size).to(device)\n",
    "        atten_weight_default = torch.zeros(batch_size,1, 27).to(device)\n",
    "        for k in range(1,len(y)):\n",
    "          if attention == \"Yes\":\n",
    "              \n",
    "              decoder_output, decoder_hidden, atten_weight = decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "              atten_weight_default = torch.cat((atten_weight_default, atten_weight), dim = 1)\n",
    "          else:\n",
    "              decoder_output, decoder_hidden= decoder(decoder_input, decoder_hidden)\n",
    "          max_prob, index = decoder_output.topk(1) # max_prob shape (1, batch_size, 1)\n",
    "          decoder_output = torch.squeeze(decoder_output)\n",
    "          loss += loss_fun(decoder_output, y[k].long())\n",
    "          pred[k-1]= torch.squeeze(index)\n",
    "          decoder_input = index\n",
    "        if attention == \"Yes\":\n",
    "            atten_weights = torch.cat((atten_weights, atten_weight_default[:, 1:, :]), dim = 0)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        correct += count_exact_matches(pred.T,y[1:,:].T)\n",
    "        predictions = torch.cat((predictions, pred), dim=1)\n",
    "\n",
    "        \n",
    "    avg_loss = running_loss / (len(data) * seq_len)\n",
    "    print(\"correct =\", correct)\n",
    "    avg_acc = 100 * (correct / (len(data)))\n",
    "    if attention == \"Yes\":\n",
    "        return avg_loss, avg_acc, predictions, atten_weights[1:, :, :]\n",
    "    else:\n",
    "        return avg_loss, avg_acc, predictions\n",
    "            \n",
    "   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T23:37:00.141926Z",
     "iopub.status.busy": "2025-05-18T23:37:00.141681Z",
     "iopub.status.idle": "2025-05-18T23:37:00.166343Z",
     "shell.execute_reply": "2025-05-18T23:37:00.165677Z",
     "shell.execute_reply.started": "2025-05-18T23:37:00.141906Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(sweeps = True, test = False):\n",
    "\n",
    "    if sweeps == False: \n",
    "        configs = config_defaults  # use the default configuration which has the best hyperparameters\n",
    "    else:\n",
    "        wandb.init(config= config_defaults, project='DL_assign_3')   # if not test then run wandb sweeps\n",
    "        configs=wandb.config\n",
    "    \n",
    "    # Set batch_size as a module attribute\n",
    "    global batch_size\n",
    "    batch_size = configs['batch_size']\n",
    "       \n",
    "\n",
    "    learn_rate = configs['learn_rate']\n",
    "    batch_size = configs['batch_size']\n",
    "    hidden_size = configs['hidden_size']\n",
    "    embedding_size = configs['embedding_size']\n",
    "    num_layers_encoder = configs['num_layers_encoder']\n",
    "    num_layers_decoder = configs['num_layers_decoder']\n",
    "    cell_type = configs['cell_type']\n",
    "    bidirectional = configs['bidirectional']\n",
    "    dropout = configs['dropout']\n",
    "    teach_ratio = configs['teach_ratio']\n",
    "    epochs = configs['epochs']\n",
    "    attention = configs['attention']\n",
    "\n",
    "    if sweeps:\n",
    "       wandb.run.name='hidden_'+str(hidden_size)+'_batch_'+str(batch_size)+'_embed_size_'+str(embedding_size)+'_dropout_'+str(dropout)+'_cell_'+str(cell_type)\n",
    "\n",
    "    input_len = ipLang.n_chars\n",
    "    output_len = opLang.n_chars\n",
    "    \n",
    "    encoder = EncoderRNN(input_len, hidden_size, embedding_size, \n",
    "                 num_layers_encoder, cell_type,\n",
    "                  bidirectional, dropout, batch_size)\n",
    "    \n",
    "    if attention ==\"Yes\":\n",
    "        decoder = AttentionDecoderRNN(hidden_size, output_len, embedding_size, num_layers_decoder, \n",
    "                 cell_type, dropout, batch_size, 27)\n",
    "    else:\n",
    "        decoder = DecoderRNN(hidden_size, output_len, embedding_size, num_layers_decoder, \n",
    "                 cell_type, dropout, batch_size)#dropout not used\n",
    "    \n",
    "    train_loader = DataLoader(trainData, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(valData, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    encoder_optimizer=optim.Adam(encoder.parameters(),learn_rate)\n",
    "    decoder_optimizer=optim.Adam(decoder.parameters(),learn_rate)\n",
    "    loss_fun=nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "    seq_len = 0\n",
    "\n",
    "    # Initialize variables for early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 5\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    for i in range(epochs):\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        train_correct = 0\n",
    "\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "\n",
    "        for j,(train_x,train_y) in enumerate(train_loader):\n",
    "            train_x = train_x.to(device)\n",
    "            train_y = train_y.to(device)\n",
    "\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "\n",
    "            train_x=train_x.T\n",
    "            train_y=train_y.T\n",
    "            # print(\"train_x.shapetrain_x.shape)\n",
    "            seq_len = len(train_y)\n",
    "            encoder_hidden=encoder.initHidden(train_x.shape[1])\n",
    "            # for LSTM encoder_hidden shape ((num_layers * num_directions, batch_size,hidden_size),(self.num_layers * num_directions, batch_size, hidden_size))\n",
    "            encoder_output,encoder_hidden = encoder(train_x,encoder_hidden)\n",
    "            # encoder_hidden shape (num_layers, batch_size, hidden_size)\n",
    "            \n",
    "            \n",
    "            # lets move to the decoder\n",
    "            decoder_input = train_y[0] # shape (1, batch_size)\n",
    "           \n",
    "            # Handle different numbers of layers in the encoder and decoder\n",
    "            if num_layers_encoder != num_layers_decoder:\n",
    "                if num_layers_encoder < num_layers_decoder:\n",
    "                    remaining_layers = num_layers_decoder - num_layers_encoder\n",
    "                    # Copy all encoder hidden layers and then repeat the top layer\n",
    "                    if cell_type == \"LSTM\":\n",
    "                        top_layer_hidden = (encoder_hidden[0][-1].unsqueeze(0), encoder_hidden[1][-1].unsqueeze(0))\n",
    "                        extra_hidden = (top_layer_hidden[0].repeat(remaining_layers, 1, 1), top_layer_hidden[1].repeat(remaining_layers, 1, 1))\n",
    "                        decoder_hidden = (torch.cat((encoder_hidden[0], extra_hidden[0]), dim=0), torch.cat((encoder_hidden[1], extra_hidden[1]), dim=0))\n",
    "                    else:\n",
    "                        top_layer_hidden = encoder_hidden[-1].unsqueeze(0) #top_layer_hidden shape (1, batch_size, hidden_size)\n",
    "                        extra_hidden = top_layer_hidden.repeat(remaining_layers, 1, 1)\n",
    "                        decoder_hidden = torch.cat((encoder_hidden, extra_hidden), dim=0)\n",
    "  \n",
    "                else:\n",
    "                    # Slice the hidden states of the encoder to match the decoder layers\n",
    "                    if cell_type == \"LSTM\":\n",
    "                        decoder_hidden = (encoder_hidden[0][-num_layers_decoder:], encoder_hidden[1][-num_layers_decoder:])\n",
    "                    else :\n",
    "                        decoder_hidden = encoder_hidden[-num_layers_decoder:]\n",
    "            else:\n",
    "                decoder_hidden = encoder_hidden\n",
    "            \n",
    "            loss = 0\n",
    "            correct = 0\n",
    "           \n",
    "            for k in range(0, len(train_y)-1):\n",
    "                \n",
    "                if attention == \"Yes\":\n",
    "                    decoder_output, decoder_hidden, atten_weights = decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "                else:\n",
    "                    decoder_output, decoder_hidden= decoder(decoder_input, decoder_hidden) # decoder_output shape (1, batch_size, output_size)\n",
    "\n",
    "                max_prob, index = decoder_output.topk(1) # max_prob shape (1, batch_size, 1)\n",
    "                index = torch.squeeze(index) # shape (batch_size)\n",
    "                decoder_output = torch.squeeze(decoder_output)\n",
    "                loss += loss_fun(decoder_output, train_y[k+1].long())\n",
    "                \n",
    "                correct += (index == train_y[k+1]).sum().item()\n",
    "\n",
    "                # Apply teacher forcing\n",
    "                use_teacher_forcing = True if random.random() < teach_ratio else False\n",
    "\n",
    "                if use_teacher_forcing:\n",
    "                    decoder_input = train_y[k+1]\n",
    "                \n",
    "                else:\n",
    "                    decoder_input = index\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            train_correct += correct\n",
    "            loss.backward()\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "        \n",
    "\n",
    "        # find train loss and accuracy and print + log to wandb\n",
    "        if attention == \"Yes\":\n",
    "            _, train_accuracy,_, _ = evaluate(trainData,encoder, decoder,output_len,batch_size,hidden_size,num_layers_encoder,num_layers_decoder, cell_type, attention)\n",
    "        else:\n",
    "            _, train_accuracy,_= evaluate(trainData,encoder, decoder,output_len,batch_size,hidden_size,num_layers_encoder,num_layers_decoder, cell_type, attention)\n",
    "        \n",
    "        print(f\"epoch {i}, training loss {running_loss/(len(trainData)* seq_len)}, training accuracy {train_accuracy}\")\n",
    "        if sweeps:\n",
    "            wandb.log({\"epoch\": i, \"train_loss\": running_loss/(len(trainData)* seq_len), \"train_accuracy\": train_accuracy})\n",
    "        \n",
    "        # # find validation loss and accuracy and print + log to wandb\n",
    "        if attention == \"Yes\":\n",
    "            val_loss, val_accuracy,_, _ = evaluate(valData,encoder, decoder,output_len,batch_size,hidden_size,num_layers_encoder,num_layers_decoder, cell_type, attention)\n",
    "        else:\n",
    "            val_loss, val_accuracy,_ = evaluate(valData,encoder, decoder,output_len,batch_size,hidden_size,num_layers_encoder,num_layers_decoder, cell_type, attention)\n",
    "        \n",
    "        print(f\"epoch {i}, validation loss {val_loss}, validation accuracy {val_accuracy}\")\n",
    "        if sweeps:\n",
    "            wandb.log({\"val_loss\": val_loss, \"val_accuracy\": val_accuracy})\n",
    "\n",
    "        # Check for early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_without_improvement = 0\n",
    "            # Save the model weights\n",
    "            torch.save(encoder.state_dict(), 'best_encoder.pt')\n",
    "            torch.save(decoder.state_dict(), 'best_decoder.pt')\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(\"Early stopping triggered. No improvement in validation loss.\")\n",
    "                break\n",
    "        \n",
    "    \n",
    "    # if testing mode is on print the test accuracy \n",
    "    if test:\n",
    "        # Load the best model weights\n",
    "        encoder.load_state_dict(torch.load('best_encoder.pt'))\n",
    "        decoder.load_state_dict(torch.load('best_decoder.pt'))\n",
    "        if attention == \"Yes\":\n",
    "            _, test_accuracy, pred, atten_weights = evaluate(testData,encoder, decoder,output_len,batch_size,hidden_size,num_layers_encoder,num_layers_decoder, cell_type, attention)\n",
    "        else:\n",
    "            _, test_accuracy, pred = evaluate(testData,encoder, decoder,output_len,batch_size,hidden_size,num_layers_encoder,num_layers_decoder, cell_type, attention)\n",
    "        print(f\"test accuracy {test_accuracy}\")\n",
    "\n",
    "    if attention == \"Yes\":\n",
    "        return pred, atten_weights\n",
    "    else:\n",
    "        return pred\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T23:37:00.167228Z",
     "iopub.status.busy": "2025-05-18T23:37:00.167034Z",
     "iopub.status.idle": "2025-05-18T23:37:00.197008Z",
     "shell.execute_reply": "2025-05-18T23:37:00.196322Z",
     "shell.execute_reply.started": "2025-05-18T23:37:00.167213Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def translate_prediction(input_dict , input, output_dict, pred,target):\n",
    "    \n",
    "    '''pred in shape of seq_len-1 * dataset_size\n",
    "       target in shape datasize * seq_len-1\n",
    "    '''\n",
    "    pred = pred.T # shape datasize * seq len-1\n",
    "    pred = pred[1:, :-1] # ignore last index of each row\n",
    "    input = input[:, :-1] # ignore  last index of each row\n",
    "    target = target[:, 1:-1] # ignore last index of each row\n",
    "    print(f\"pred shape {pred.shape}, input shape {input.shape}, target shape {target.shape}\")\n",
    "    predictions = [] \n",
    "    Input = [] \n",
    "    Target = []\n",
    "    for i in range(len(pred)):\n",
    "        \n",
    "        pred_word=\"\"\n",
    "        input_word=\"\"\n",
    "        target_word = \"\"\n",
    "\n",
    "        for j in range(pred.shape[1]):\n",
    "\n",
    "            # Ignore padding\n",
    "            if(target[i][j].item() != 0):\n",
    "              \n",
    "              pred_word += output_dict[pred[i][j].item()]\n",
    "              target_word += output_dict[target[i][j].item()]\n",
    "                    \n",
    "        for j in range(input.shape[1]):\n",
    "            \n",
    "               if(input[i][j].item()!=0):\n",
    "                    \n",
    "                    input_word += input_dict[input[i][j].item()]   \n",
    "\n",
    "        # Append words in respective List\n",
    "        \n",
    "        predictions.append(pred_word)\n",
    "        Input.append(input_word)         \n",
    "        Target.append(target_word)   \n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\"input\": Input, \"predicted\": predictions,\"Actual\":Target})\n",
    "    return df\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T23:37:00.197977Z",
     "iopub.status.busy": "2025-05-18T23:37:00.197731Z",
     "iopub.status.idle": "2025-05-18T23:37:00.221241Z",
     "shell.execute_reply": "2025-05-18T23:37:00.220742Z",
     "shell.execute_reply.started": "2025-05-18T23:37:00.197958Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "  'name': 'sweepDL',  \n",
    "  'method': 'bayes',\n",
    "  'metric': {\n",
    "        'name': 'val_accuracy',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "  'parameters': {\n",
    "        \n",
    "        'learn_rate': {\n",
    "            'values': [0.01, 0.001, 0.001]\n",
    "        },\n",
    "        'embedding_size': {\n",
    "            'values': [32, 64, 128, 256, 512, 1024]\n",
    "        },\n",
    "        'batch_size':{\n",
    "            'values':[16, 32, 64, 128, 256]\n",
    "        },\n",
    "        'hidden_size':{\n",
    "            'values':[32, 64, 128, 256, 512, 1024]\n",
    "        },\n",
    "        'teach_ratio':{\n",
    "            'values':[0.4, 0.5, 0.6]\n",
    "        },\n",
    "        'dropout':{\n",
    "            'values':[0, 0.2, 0.4]\n",
    "        },\n",
    "        'cell_type':{\n",
    "            'values':[\"RNN\", \"LSTM\", \"GRU\"]\n",
    "        },\n",
    "        'bidirectional':{\n",
    "            'values' : [\"Yes\",\"No\"]\n",
    "        },\n",
    "        'num_layers_decoder':{\n",
    "            'values': [1,2, 3, 4]\n",
    "        },\n",
    "        'num_layers_encoder':{\n",
    "            'values': [1,2,3,4]\n",
    "        },\n",
    "        'epochs':{\n",
    "            'values': [10, 15, 20, 25, 30]\n",
    "        },\n",
    "        'attention':{\n",
    "            'values': [\"Yes\"]\n",
    "        }\n",
    "           \n",
    "    }\n",
    "}\n",
    "config_defaults={\n",
    "    'learn_rate' : 0.001,\n",
    "    'embedding_size': 32,\n",
    "    'batch_size': 256,\n",
    "    'hidden_size' : 1024,\n",
    "    'num_layers_encoder': 3,\n",
    "    'num_layers_decoder': 3,\n",
    "    'bidirectional': 'No',\n",
    "    'cell_type': \"LSTM\",\n",
    "    'teach_ratio': 0.6,\n",
    "    'dropout': 0.4,\n",
    "    'epochs': 15,\n",
    "    'attention': \"No\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T23:37:00.222097Z",
     "iopub.status.busy": "2025-05-18T23:37:00.221861Z",
     "iopub.status.idle": "2025-05-18T23:37:06.797579Z",
     "shell.execute_reply": "2025-05-18T23:37:06.797058Z",
     "shell.execute_reply.started": "2025-05-18T23:37:00.222076Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\vedpr\\_netrc\n",
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\vedpr\\_netrc\n",
      "wandb: Currently logged in as: ma23c047 (ma23c047-indian-institute-of-technology-madras) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "wandb: Currently logged in as: ma23c047 (ma23c047-indian-institute-of-technology-madras) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key =\"f15dba29e56f32e9c31d598bce5bc7a3c76de62e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T23:47:04.123139Z",
     "iopub.status.busy": "2025-05-18T23:47:04.122856Z",
     "iopub.status.idle": "2025-05-18T23:47:52.349585Z",
     "shell.execute_reply": "2025-05-18T23:47:52.348991Z",
     "shell.execute_reply.started": "2025-05-18T23:47:04.123121Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: hasf9bl1\n",
      "Sweep URL: https://wandb.ai/ma23c047-indian-institute-of-technology-madras/DA6401_A3/sweeps/hasf9bl1\n",
      " hasf9bl1\n",
      "Sweep URL: https://wandb.ai/ma23c047-indian-institute-of-technology-madras/DA6401_A3/sweeps/hasf9bl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: lxmkhfkc with config:\n",
      "wandb: \tattention: Yes\n",
      "wandb: \tbatch_size: 32\n",
      "wandb: \tbidirectional: Yes\n",
      "wandb: \tcell_type: GRU\n",
      "wandb: \tdropout: 0.4\n",
      "wandb: \tembedding_size: 128\n",
      "wandb: \tepochs: 10\n",
      "wandb: \thidden_size: 128\n",
      "wandb: \tlearn_rate: 0.01\n",
      "wandb: \tnum_layers_decoder: 2\n",
      "wandb: \tnum_layers_encoder: 1\n",
      "wandb: \tteach_ratio: 0.5\n",
      "wandb: \tattention: Yes\n",
      "wandb: \tbatch_size: 32\n",
      "wandb: \tbidirectional: Yes\n",
      "wandb: \tcell_type: GRU\n",
      "wandb: \tdropout: 0.4\n",
      "wandb: \tembedding_size: 128\n",
      "wandb: \tepochs: 10\n",
      "wandb: \thidden_size: 128\n",
      "wandb: \tlearn_rate: 0.01\n",
      "wandb: \tnum_layers_decoder: 2\n",
      "wandb: \tnum_layers_encoder: 1\n",
      "wandb: \tteach_ratio: 0.5\n",
      "wandb: ERROR Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: ERROR Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'DL_assign_3' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\vedpr\\Downloads\\wandb\\run-20250519_132747-lxmkhfkc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ma23c047-indian-institute-of-technology-madras/DA6401_A3/runs/lxmkhfkc' target=\"_blank\">ethereal-sweep-1</a></strong> to <a href='https://wandb.ai/ma23c047-indian-institute-of-technology-madras/DA6401_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c047-indian-institute-of-technology-madras/DA6401_A3/sweeps/hasf9bl1' target=\"_blank\">https://wandb.ai/ma23c047-indian-institute-of-technology-madras/DA6401_A3/sweeps/hasf9bl1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ma23c047-indian-institute-of-technology-madras/DA6401_A3' target=\"_blank\">https://wandb.ai/ma23c047-indian-institute-of-technology-madras/DA6401_A3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ma23c047-indian-institute-of-technology-madras/DA6401_A3/sweeps/hasf9bl1' target=\"_blank\">https://wandb.ai/ma23c047-indian-institute-of-technology-madras/DA6401_A3/sweeps/hasf9bl1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ma23c047-indian-institute-of-technology-madras/DA6401_A3/runs/lxmkhfkc' target=\"_blank\">https://wandb.ai/ma23c047-indian-institute-of-technology-madras/DA6401_A3/runs/lxmkhfkc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedpr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hidden_128_batch_32_embed_size_128_dropout_0.4_cell_GRU</strong> at: <a href='https://wandb.ai/ma23c047-indian-institute-of-technology-madras/DA6401_A3/runs/lxmkhfkc' target=\"_blank\">https://wandb.ai/ma23c047-indian-institute-of-technology-madras/DA6401_A3/runs/lxmkhfkc</a><br> View project at: <a href='https://wandb.ai/ma23c047-indian-institute-of-technology-madras/DA6401_A3' target=\"_blank\">https://wandb.ai/ma23c047-indian-institute-of-technology-madras/DA6401_A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250519_132747-lxmkhfkc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Run lxmkhfkc errored:\n",
      "wandb: ERROR Traceback (most recent call last):\n",
      "wandb: ERROR   File \"C:\\Users\\vedpr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\wandb\\agents\\pyagent.py\", line 306, in _run_job\n",
      "wandb: ERROR     self._function()\n",
      "wandb: ERROR   File \"C:\\Users\\vedpr\\AppData\\Local\\Temp\\ipykernel_40568\\1713152420.py\", line 146, in train\n",
      "wandb: ERROR     _, train_accuracy,_, _ = evaluate(trainData,encoder, decoder,output_len,batch_size,hidden_size,num_layers_encoder,num_layers_decoder, cell_type, attention)\n",
      "wandb: ERROR                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "wandb: ERROR   File \"C:\\Users\\vedpr\\AppData\\Local\\Temp\\ipykernel_40568\\3841131653.py\", line 28, in evaluate\n",
      "wandb: ERROR     encoder_output,encoder_hidden = encoder(x,encoder_hidden)\n",
      "wandb: ERROR                                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "wandb: ERROR   File \"C:\\Users\\vedpr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py\", line 1739, in _wrapped_call_impl\n",
      "wandb: ERROR     return self._call_impl(*args, **kwargs)\n",
      "wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "wandb: ERROR   File \"C:\\Users\\vedpr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py\", line 1750, in _call_impl\n",
      "wandb: ERROR     return forward_call(*args, **kwargs)\n",
      "wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "wandb: ERROR   File \"C:\\Users\\vedpr\\AppData\\Local\\Temp\\ipykernel_40568\\3898396692.py\", line 31, in forward\n",
      "wandb: ERROR     output, hidden = self.rnn(embedded, hidden)\n",
      "wandb: ERROR                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "wandb: ERROR   File \"C:\\Users\\vedpr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py\", line 1739, in _wrapped_call_impl\n",
      "wandb: ERROR     return self._call_impl(*args, **kwargs)\n",
      "wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "wandb: ERROR   File \"C:\\Users\\vedpr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py\", line 1750, in _call_impl\n",
      "wandb: ERROR     return forward_call(*args, **kwargs)\n",
      "wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "wandb: ERROR   File \"C:\\Users\\vedpr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\rnn.py\", line 1391, in forward\n",
      "wandb: ERROR     self.check_forward_args(input, hx, batch_sizes)\n",
      "wandb: ERROR   File \"C:\\Users\\vedpr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\rnn.py\", line 366, in check_forward_args\n",
      "wandb: ERROR     self.check_hidden_size(hidden, expected_hidden_size)\n",
      "wandb: ERROR   File \"C:\\Users\\vedpr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\rnn.py\", line 347, in check_hidden_size\n",
      "wandb: ERROR     raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\n",
      "wandb: ERROR RuntimeError: Expected hidden size (2, 12, 128), got [2, 32, 128]\n",
      "wandb: ERROR \n"
     ]
    }
   ],
   "source": [
    "# Run sweep\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"DA6401_A3\")\n",
    "wandb.agent(sweep_id, function=train,count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7437239,
     "sourceId": 11837623,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
